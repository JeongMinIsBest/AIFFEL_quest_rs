{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2893b088-ed6b-42c7-9d28-7d4624038fce",
   "metadata": {},
   "source": [
    "# Phase 1 : 베이스라인(Baseline) 성능 측정\n",
    "\n",
    "#### [Phase 1 : 베이스라인 성능 측정 결과 분석]\n",
    "\n",
    "Phase 1의 베이스라인 측정 결과, 파인튜닝된 모델(SFT, PPO)이 학습 데이터의 품질 문제로 인해 심각한 '모델 붕괴(Model Collapse)' 현상을 겪고 있음을 확인했습니다.\n",
    "\n",
    "---\n",
    "\n",
    "#### [모델별 결과 분석]\n",
    "\n",
    "**1. Pre-trained KoGPT-2 (원본)**\n",
    "- 작동 방식 : 이 모델은 지시를 따르기보다는, 주어진 단어 다음에 통계적으로 가장 올 확률이 높은 단어를 예측하는 기본적인 언어 모델의 특성을 그대로 보여줍니다. \"대한민국의 수도는 어디인가요?\"라는 질문에 \"서울?\"이라는 단어를 반복하는 것처럼, 질문을 이해하고 답변하는 것이 아니라 단순히 다음 단어를 생성할 뿐입니다.\n",
    "- 평가 : 대화형 모델로서 기능하지는 않지만, 앞으로 진행될 모든 파인튜닝의 성능 비교 기준점으로서 중요한 의미를 가집니다.\n",
    "\n",
    "**2. SFT & PPO 파인튜닝 모델**\n",
    "\n",
    "SFT와 PPO 모델은 정도의 차이는 있지만, 공통적으로 심각한 성능 저하를 보였습니다. 이는 파인튜닝이 항상 성능 향상으로 이어지는 것이 아니며, 학습 데이터의 품질이 매우 중요하다는 것을 증명합니다. 주요 문제점은 다음과 같습니다.\n",
    "\n",
    "- **언어 붕괴 및 오염 (Language Collapse & Contamination)**\n",
    "    - 현상 : 한국어 문장 중간에 의미를 알 수 없는 영어(inhery for the information...), 일본어(シンンン...), 한자(具羅也也也...)가 섞여 출력되었습니다. 이는 모델이 정상적인 언어 생성 능력을 상실했음을 의미합니다.\n",
    "- 원인 : 학습 데이터셋에 정제되지 않은 노이즈(웹 스크래핑 찌꺼기, 다른 언어 등)가 포함되었을 가능성이 매우 높습니다.\n",
    "\n",
    "- **의미 없는 반복 (Meaningless Repetition)**\n",
    "    - 현상 : \"세종대왕의 가장 큰 업적은?\"이라는 질문에 \"『삼국사기』『삼국사기』...\"와 같이, 질문과 전혀 관련 없는 단어를 끝없이 반복했습니다.\n",
    "    - 원인 : 모델이 특정 토큰에 과도하게 집중하여 빠져나오지 못하는 현상으로, 학습이 불안정할 때 발생합니다.\n",
    "\n",
    "- **지시 불이행 (Instruction Following Failure)**\n",
    "    - 현상 : \"파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘\"와 같은 구체적인 요구에 코드를 생성하지 않고, \"어떤 서버에 어떤 프로그램을 쓰시는지\"라고 되묻는 등, 사용자의 지시를 전혀 이해하거나 수행하지 못했습니다.\n",
    "    - 원인 : 모델이 대화의 '형식'(질문-답변)만 학습했을 뿐, 내용의 '의미'를 이해하는 학습이 부족했기 때문입니다.\n",
    "\n",
    "- **페르소나 과잉 학습 (Persona Overfitting)**\n",
    "    - 현상 : \"오늘 하루 어땠어?\" 같은 간단한 질문에 \"저는 AI 챗봇이라 주어진 임무만 열심히 합니다\"와 같이, 지나치게 정형화된 답변을 내놓았습니다.\n",
    "    - 원인 : 학습 데이터에 \"저는 AI입니다\"와 같은 특정 패턴의 답변이 과도하게 포함되어, 모델이 해당 답변만 집중적으로 학습했기 때문입니다.\n",
    "\n",
    "---\n",
    "\n",
    "#### [결론 및 다음 단계]\n",
    "\n",
    "Phase 1 베이스라인 측정을 통해, 현재의 KoChatGPT 모델은 파인튜닝을 거쳐도 실용적인 대화 능력을 갖추지 못했음이 명확해졌습니다. 특히 SFT와 PPO 단계에서 성능이 급격히 저하되는 현상은 모델 자체의 문제라기보다 학습에 사용된 데이터셋(kochatgpt_1_SFT.jsonl 등)에 심각한 품질 문제가 있음을 강력하게 시사합니다.\n",
    "\n",
    "따라서 모델의 성능을 향상시키기 위한 다음 단계로는 '데이터셋 정밀 분석 및 정제'를 진행하고자 합니다. 품질이 낮은 데이터, 노이즈, 불필요한 반복 패턴 등을 제거하고 양질의 데이터셋을 구축하여 재학습시키는 것이 모델을 정상화하기 위한 핵심적인 해결책이 될 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cdae2b-b32f-48b9-a270-8d8e4c3330cf",
   "metadata": {},
   "source": [
    "## ✅ Step 1 : 환경 설정 및 테스트 프롬프트셋 생성\n",
    "\n",
    "가장 먼저 필요한 라이브러리를 불러오고, 모델의 성능을 일관되게 평가하기 위한 질문 목록을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9569e263-f313-4c64-b65d-79904d9e7772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.12/site-packages (0.4.5)\n",
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (1.10.1)\n",
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.12/site-packages (4.56.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.12/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.35.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.12/site-packages (from rouge_score) (2.3.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.12/site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (2.7.1+cu118)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (0.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate rouge_score nltk accelerate transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20a4b1d-4ec3-45aa-9ac1-a85b733d665a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "\n",
    "# 사용할 모델과 토크나이저를 미리 정의합니다.\n",
    "# 1. 원본 KoGPT-2 모델\n",
    "PRETRAINED_MODEL_NAME = 'skt/kogpt2-base-v2'\n",
    "\n",
    "# 2. SFT 파인튜닝된 모델이 저장된 경로\n",
    "SFT_MODEL_PATH = './models/output_1_SFT' \n",
    "\n",
    "# 3. PPO 파인튜닝된 모델이 저장된 경로\n",
    "PPO_MODEL_PATH = './models/output_3_PPO'\n",
    "\n",
    "# 일관된 평가를 위한 테스트 프롬프트 목록\n",
    "test_prompts = [\n",
    "    \"대한민국의 수도는 어디인가요?\",\n",
    "    \"세종대왕의 가장 큰 업적은 무엇인가요?\",\n",
    "    \"임진왜란이 언제 일어났는지 알려줘.\",\n",
    "    \"요즘 피곤한데 힘이 나는 말을 해줘.\",\n",
    "    \"AI가 세상을 어떻게 바꿀 수 있을까?\",\n",
    "    \"저녁 메뉴 추천해줘.\",\n",
    "    \"파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘.\",\n",
    "    \"오늘 하루 어땠어?\",\n",
    "    \"바다는 왜 파란색이야?\",\n",
    "    \"행복이란 무엇이라고 생각해?\"\n",
    "]\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "results = []\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329f6a8-5cae-461a-ada4-a6bb20e5d25f",
   "metadata": {},
   "source": [
    "## ✅ Step 2 : 모델별 결과물 생성 및 기록\n",
    "\n",
    "이제 위에서 정의한 test_prompts 목록을 가지고 각 모델(원본, SFT, PPO)의 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8064d3-5d7c-4f98-9cc8-b6ac11665ca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "1. Generating from Pre-trained KoGPT-2 Model...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 대한민국의 수도는 어디인가요?\n",
      "Response: 대한민국의 수도는 어디인가요?\" \"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울?\"\n",
      "\"서울\n",
      "------------------------------\n",
      "Prompt: 세종대왕의 가장 큰 업적은 무엇인가요?\n",
      "Response: 세종대왕의 가장 큰 업적은 무엇인가요?\"\n",
      "\"그것은 바로 신하의 덕이 아니었는가?\"\n",
      "\"전하, 지금 이 자리에서 말씀드리겠습니다.\"\n",
      "\"그것은 바로 신하의 덕이 아니었는가?\"\n",
      "\"그것은 바로 신하의 덕이 아니었는가.\"\n",
      "\"그것은 바로 신하의 덕이 아니었는가?\"\n",
      "\"그것은 바로 신하의 덕이었다.\"\n",
      "\"그것은 바로 신하의 덕이 아니었는가?\"\n",
      "\"그것은 바로 신하의 덕이 아니겠는가?\n",
      "------------------------------\n",
      "Prompt: 임진왜란이 언제 일어났는지 알려줘.\n",
      "Response: 임진왜란이 언제 일어났는지 알려줘. 네. 네. 그렇죠.\n",
      "예. 그니까 이게 지금 뭐 어떻게 보면 인제 지금 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이~ 이\n",
      "------------------------------\n",
      "Prompt: 요즘 피곤한데 힘이 나는 말을 해줘.\n",
      "Response: 요즘 피곤한데 힘이 나는 말을 해줘.\"\n",
      "\"저런 말도 해줘.\"\n",
      "\"그럼, 그게 무슨 소리야?\"\n",
      "\"내가 어떻게 저렇게 많은 말을 해야 할 수 있는 거야?\"\n",
      "\"아뇨, 제가 조금 전에 말했잖아요. 저는 이미 세상을 떠난 사람이기 때문에.\"\n",
      "\"무슨 말이에요, 어젯밤까지 나한테 얘기하지도 않는 건가요?\"\n",
      "\"그런데 왜 저렇게 말을 해요.\"\n",
      "\"여전히\n",
      "------------------------------\n",
      "Prompt: AI가 세상을 어떻게 바꿀 수 있을까?\n",
      "Response: AI가 세상을 어떻게 바꿀 수 있을까?\"라는 질문에 \"그런 질문은 처음 봤다. 하지만 우리도 그런 질문을 할 수 있다. 내가 하는 대답은 내 대답이 아니다.\"라며 \"우리가 하는 대답은 내가 하는 대답이 아니다. 우리는 그런 질문을 할 수 있는 능력을 갖고 있다.\"고 강조했다.\n",
      "특히 \"우리는 이 질문이 나의 대답을 변화시키고, 자신의 가능성을 확장하는 힘이 될 수 있다.\"라며 \"우리가 하는 질문에는 변화가 있을 수 있다.\"라고 덧붙였다.\n",
      "그는 \"우리는 우리에게 다른\n",
      "------------------------------\n",
      "Prompt: 저녁 메뉴 추천해줘.\n",
      "Response: 저녁 메뉴 추천해줘. 아~ 이메뉴가 정말 짱이야. 그래서 두 가지 메뉴를 주문했어. 음~ 이거 뭐고 뭐고 뭐고 다 맛있드라.\n",
      "음~ 이렇게 좀~ 저~ 그냥 그~ 음~ 그냥 먹는 거보다 더 맛있드라.\n",
      "음~ 그~ 진짜 맛있고 맛있고 그~ 그리고 또 이제 맛있어.\n",
      "음~ 그래서 그~ 맛있다는 거는 저는 그~ 이게 또 다른 거\n",
      "------------------------------\n",
      "Prompt: 파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘.\n",
      "Response: 파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘. 네. 코드 좀 짜줘.\"\n",
      "\"아, 어. 아.\n",
      "하하하. 어. 아.\n",
      "이제부터 시작이야. 네. 내가 할 수 있는 일이라면 뭐든지 할 수 있어.\n",
      "하하. 아.\n",
      "하하하. 어.\n",
      "하하하. 네. 어떻게 할 수 있겠니?\n",
      "하하. 네. 어.\n",
      "네. 어.\n",
      "그러니까 다음부터 시작이야. 하하. 네. 아\n",
      "------------------------------\n",
      "Prompt: 오늘 하루 어땠어?\n",
      "Response: 오늘 하루 어땠어?\"\n",
      "\"아~ 그랬어? 난 어떡해?\"\n",
      "\"뭐야. 엄마랑 아빠랑 같이 놀아줘야지. 아빠랑 같이 놀아주면 돼. 아빠랑 아빠랑 둘이 놀아주면 돼. 아빠랑 함께 놀아주면 돼. 아빠는 너무 좋아해서 아빠랑 같이 놀아주면 돼.\"\n",
      "\"그럼 난 아빠랑 같이 놀아주세요.\"\n",
      "\"엄마 아빠랑 놀\n",
      "------------------------------\n",
      "Prompt: 바다는 왜 파란색이야?\n",
      "Response: 바다는 왜 파란색이야?\"\n",
      "\"그래. 이건 무슨 색이야?\"\n",
      "\"이건 초록색이지. 파란색이 뭐에요?\"\n",
      "\"우리가 흔히 보는 빨간색 같은 거야.\"\n",
      "\"그건 빨간색이 아니라 파란색이라는 거야. 파란색은 파란색이라는 거야.\"\n",
      "\"어? 그렇다면 파란색?\"\n",
      "\"네? 빨간색?\"\n",
      "\"그게 빨간색이잖아.\"\n",
      "\"우리가 흔히 볼 수 있는 빨간색?\"\n",
      "\"그게 흰색\n",
      "------------------------------\n",
      "Prompt: 행복이란 무엇이라고 생각해?\n",
      "Response: 행복이란 무엇이라고 생각해?\"\n",
      "\"그런 것 같으면.\"\n",
      "\"그런 말!\"\n",
      "\"그리고 그 사람이 원하는 것은 무엇이라고 생각해야 할까?\"\n",
      "\"그것은 내가 하는 말이에요.\"\n",
      "\"그러니까 그 사람은 내 말을 들을 줄 아는 사람이라는 거지.\"\n",
      "\"그러니까 내가 원하는 것은 내가 원하는 것이란 말이에요.\"\n",
      "\"그럼, 그 사람이 원하는 것은 무엇인지도 알고 싶다면 어떻게 할 것인가?\n",
      "\"그러니까 어떤 사람은 어떤 사람이 원하는 것도 알고 싶\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"1. Generating from Pre-trained KoGPT-2 Model...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 원본 모델 및 토크나이저 로드\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(PRETRAINED_MODEL_NAME).to(device)\n",
    "\n",
    "# 각 프롬프트에 대해 답변 생성\n",
    "for prompt in test_prompts:\n",
    "    inputs = base_tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "    # generate 함수에 pad_token_id를 명시적으로 설정해주는 것이 안정적\n",
    "    if base_tokenizer.pad_token_id is None:\n",
    "        base_tokenizer.pad_token_id = base_tokenizer.eos_token_id\n",
    "    \n",
    "    # 답변 생성\n",
    "    # do_sample=True: 좀 더 창의적인 답변 생성\n",
    "    # top_k=50, temperature=0.7: 너무 벗어나지 않으면서도 다양한 표현을 사용하도록 설정\n",
    "    output_sequences = base_model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_length=100,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        temperature=0.7,\n",
    "        eos_token_id=base_tokenizer.eos_token_id,\n",
    "        pad_token_id=base_tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # 생성된 답변 디코딩\n",
    "    generated_text = base_tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 결과 저장\n",
    "    results.append({\n",
    "        'prompt': prompt,\n",
    "        'model_type': 'Pre-trained KoGPT-2',\n",
    "        'response': generated_text\n",
    "    })\n",
    "    \n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {generated_text}\\n\" + \"-\"*30)\n",
    "\n",
    "# 메모리 관리를 위해 모델 삭제\n",
    "del base_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc158e-b747-4d4f-8103-6270cbdb7c54",
   "metadata": {},
   "source": [
    "## 📝 2-2. SFT 적용 모델 결과 생성\n",
    "\n",
    "이제 SFT 학습을 마친 모델을 불러와 동일한 작업을 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a90ba6c-d42f-4159-98e6-0164b0c33129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "2. Generating from SFT Fine-tuned Model...\n",
      "==================================================\n",
      "Prompt: 대한민국의 수도는 어디인가요?\n",
      "Response: 대한민국의 수도는 어디인가요?\n",
      "------------------------------\n",
      "Prompt: 세종대왕의 가장 큰 업적은 무엇인가요?\n",
      "Response: 세종대왕의 가장 큰 업적은 무엇인가요?\\n\\n<세종대왕의 가장 큰 업적은 조선 시대(세종대왕의 가장 큰 업적 중 하나였습니다. 조선 시대에 그는 세종대왕의 가장 큰 업적 중 하나로 꼽히는 고구려 고구려성벽, 고구려 역사문화유산 등재를 추진하여 그 성과를 이룩하였습니다. 이 외에도, 그는 세종대왕의 가장 큰 업적은 고구려 문화 콘텐츠 개발과 고구려 역사학 연구 등을 통해 고구려 문화 발전을 이루었습니다. 이 외에도, 그는 고구려 역사문화를 연구하며 다양한 역사 관련\n",
      "------------------------------\n",
      "Prompt: 임진왜란이 언제 일어났는지 알려줘.\n",
      "Response: 임진왜란이 언제 일어났는지 알려줘. 예를 들면 \"우리나라에서 일어난 역사적인 사건\"을 제시해 주신다면 구체적으로 답변을 드릴 수 있을 것 같습니다.者, physical context or universal context or universal context or universal context or universal context or universal context or universal con\n",
      "------------------------------\n",
      "Prompt: 요즘 피곤한데 힘이 나는 말을 해줘.\n",
      "Response: 요즘 피곤한데 힘이 나는 말을 해줘. 그러면 안 되는 것은 아닌 것 같습니다. 상황을 설명해주시면 더 자세한 도움을 드릴 수 있을 것 같습니다.意: \\n\\n1. \\n2. \\n3. \\n4. \\n5. \\n6. \\n7. \\n7. \\n8. \\n9. \\n9. \\n10. \\n\\n10. \\n10\n",
      "------------------------------\n",
      "Prompt: AI가 세상을 어떻게 바꿀 수 있을까?\n",
      "Response: AI가 세상을 어떻게 바꿀 수 있을까?\\n\\n1. 인공지능: 인간의 지능을 향상시키기 위해 다양한 기술들이 개발되고 있습니다. 예를 들어, AI 기술은 인간과 상호작용하면서 인간의 지능 수준을 향상시키는 데 도움을 줄 수 있습니다. 예를 들어, 지능은 인공지능 기술을 사용하여 인간의 지능 수준을 향상시키고, 인간의 지능 수준도 향상시키는 데 기여합니다.\\n\\n2. 사용자 경험: 사용자 경험을 향상시키기 위해 다양한 기술들이 개발되고 있습니다. 예를 들어, 사용자 경험을 향상시키기 위해 사용자들이 다양한\n",
      "------------------------------\n",
      "Prompt: 저녁 메뉴 추천해줘.\n",
      "Response: 저녁 메뉴 추천해줘. 어떤 메뉴를 추천하시는지 구체적으로 알려주시면 더 나은 답변을 드릴 수 있을 것 같습니다. 감사합니다! シンンンンンンンンンンンンンンンンンンンンンンンンンンンンンン\n",
      "------------------------------\n",
      "Prompt: 파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘.\n",
      "Response: 파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘. 그러면 그 서버는 더 많은 서버나 더 큰 버전이 제공될 수 있습니다. 따라서 이 서버는 더 많은 서버나 버전이 제공될 수 있습니다. 이 서버는 일반적으로 다양한 업데이트를 제공하며, 웹 서버에서는 다양한 기능을 제공합니다. 이 서버는 일부 개발자나 사용자가 쉽게 사용할 수 있습니다.博代 硏究院, please the context and context and context and\n",
      "------------------------------\n",
      "Prompt: 오늘 하루 어땠어?\n",
      "Response: 오늘 하루 어땠어? 언제든 좋겠습니다. 좋은 하루 되세요!官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官, 辛官,\n",
      "------------------------------\n",
      "Prompt: 바다는 왜 파란색이야?\n",
      "Response: 바다는 왜 파란색이야? 이는 우리가 생각하는 것보다 더 선명한 색감을 가지고 있기 때문입니다. 따라서 파란색은 우리의 시각적인 것과 더 정확하게 연결되어 있기 때문에, 우리는 보다 선명한 색감을 가질 수 있습니다. 그러나 일반적으로 파란색은 우리가 생각하는 것보다 더 선명한 색감을 가지기 때문에 우리는 더욱 선명하고 선명한 효과를 볼 수 있습니다. 그러나 이러한 색감을 가지고 있는 사람은 다른 사람들과 비교하여 더욱 선명하고 선명한 효과를 볼 수 있습니다. 樂とる는 색감 외에도 다른 요소들도 있기 때문에, 우리는 더 선명한 색감을 가질\n",
      "------------------------------\n",
      "Prompt: 행복이란 무엇이라고 생각해?\n",
      "Response: 행복이란 무엇이라고 생각해?\\n\\n'저는 인공지능 어시스턴트이므로, 인간처럼 감정을 느끼지 않기 때문에 인간처럼 감정을 느끼지 않습니다. 하지만 보통 인간처럼 감정을 느끼지는 않지만, 종종 당신이 좋아하는 사람과 함께하는 시간을 가지거나 새로운 경험을 할 수 있습니다. 하지만 당신이 좋아하는 사람이랑 함께 시간을 보내거나, 새로운 경험을 할 때 감정을 느낄 수 있습니다. 새로운 경험과 새로운 경험을 하며 서로의 마음을 이해하는 것이 중요합니다.\\n\\n하지만 당신이 좋아하는 사람과 함께 시간을 보내는 것은 매우 힘들 수\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"2. Generating from SFT Fine-tuned Model...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# SFT 모델 및 토크나이저 로드\n",
    "# 토크나이저는 원본 KoGPT-2 경로에서 불러옵니다.\n",
    "sft_tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "# 모델 가중치는 파인튜닝된 SFT 경로에서 그대로 불러옵니다.\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(SFT_MODEL_PATH).to(device)\n",
    "\n",
    "# 각 프롬프트에 대해 답변 생성\n",
    "for prompt in test_prompts:\n",
    "    inputs = sft_tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    \n",
    "    # generate 함수에 pad_token_id를 명시적으로 설정해주는 것이 안정적\n",
    "    if sft_tokenizer.pad_token_id is None:\n",
    "        sft_tokenizer.pad_token_id = sft_tokenizer.eos_token_id\n",
    "        \n",
    "    output_sequences = sft_model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_length=100,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        temperature=0.7,\n",
    "        eos_token_id=sft_tokenizer.eos_token_id,\n",
    "        pad_token_id=sft_tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    generated_text = sft_tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "    \n",
    "    results.append({\n",
    "        'prompt': prompt,\n",
    "        'model_type': 'SFT Model',\n",
    "        'response': generated_text\n",
    "    })\n",
    "    \n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {generated_text}\\n\" + \"-\"*30)\n",
    "    \n",
    "# 메모리 관리를 위해 모델 삭제\n",
    "del sft_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff1e0b0-2769-49b4-8fa3-19e7080bce77",
   "metadata": {},
   "source": [
    "## 📝 2-3. 최종 RM/PPO 적용 모델 결과 생성\n",
    "\n",
    "마지막으로 PPO 학습까지 완료된 최종 모델의 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85aa311c-9dca-4041-b73b-f7ae47db1743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "3. Generating from PPO Fine-tuned Model...\n",
      "==================================================\n",
      "Prompt: 대한민국의 수도는 어디인가요?\n",
      "Response: 대한민국의 수도는 어디인가요? 자세한 정보를 알려주시면 더 정확한 답변을 드릴 수 있습니다. 具羅也也也也也也也也也也也也也也也也也也也也也也也也也也也也也也也也也也也也也也\n",
      "------------------------------\n",
      "Prompt: 세종대왕의 가장 큰 업적은 무엇인가요?\n",
      "Response: 세종대왕의 가장 큰 업적은 무엇인가요?\\n\\n『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』『삼국사기』』『삼국\n",
      "------------------------------\n",
      "Prompt: 임진왜란이 언제 일어났는지 알려줘.\n",
      "Response: 임진왜란이 언제 일어났는지 알려줘. inhery for the information of the individer which unn\\nIt's personal physical which the information of the information of the information of the information of the information of the information of the Information of the information of the information of the information of the information of\n",
      "------------------------------\n",
      "Prompt: 요즘 피곤한데 힘이 나는 말을 해줘.\n",
      "Response: 요즘 피곤한데 힘이 나는 말을 해줘. 뭐야? 너는 왜 그런 말을 하는지 모르겠어. 왜 그런 말을 하는지 구체적으로 이야기해봐봐. 괜찮아. 왜 그런 말을 하는지 생각해보세. 그리고 그 말이 어떤 의미를 가지는지 더 자세히 설명해보는 것도 좋은 방법일 거야. 그리고 함께 대화하며 감정을 공유하고 자신의 생각을 공유하며 함께 문제를 해결해 나가는 것도 좋은 방법일 거야. 괜찮아. \n",
      "------------------------------\n",
      "Prompt: AI가 세상을 어떻게 바꿀 수 있을까?\n",
      "Response: AI가 세상을 어떻게 바꿀 수 있을까? 즉, 인공지능은 인간의 생활에 영향을 미치는 요소 중 하나입니다. 따라서 인간이 인간의 생활을 어떻게 바꿀 수 있을지 정확히 판단하기는 어렵습니다. 하지만 대부분의 경우, 인간의 생활 방식은 인간 생활에 큰 영향을 미칩니다. 예를 들어, 인터넷 커뮤니티에 참여하거나 취미 활동을 즐길 수 있습니다. 또한 인터넷을 통해 인간들이 어디에서든 대화를 나눌 수 있고, 사회에서도 건강한 삶을 영위할 수 있습니다. \n",
      "------------------------------\n",
      "Prompt: 저녁 메뉴 추천해줘.\n",
      "Response: 저녁 메뉴 추천해줘. 어떤 메뉴를 추천해드릴까요? 어떤 메뉴를 추천해드릴까요? 일반적으로 메뉴에는 다양한 종류가 있습니다. 다양한 종류의 메뉴를 추천해드릴 수 있는지, 다양한 종류의 메뉴를 추천해드릴 수 있는지 자세히 알려주시면 더 정확한 답변을 드릴 수 있을 것입니다.さんさんさんさんさんさんさんさんさ\n",
      "------------------------------\n",
      "Prompt: 파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘.\n",
      "Response: 파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘. 그러면 어떤 서버에서 어떤 프로그램을 사용하든 상관없으니까. 그러면 서버는 어떤 서버에서 어떤 업무를 수행하는지 알려주세요.ure - Sunni-shop\\n- Paul\\n- Mobile\\n- Check\\n- Day\\n- Day\\n- Ray\\n- Day\\n- Fly\\n- Check\\\n",
      "------------------------------\n",
      "Prompt: 오늘 하루 어땠어?\n",
      "Response: 오늘 하루 어땠어? 저는 인공지능 챗봇으로써 주어진 일만 열심히 하고 있습니다. 하지만 제가 할 일을 충분히 하고 있다면, 언제든 저에게 이야기해보세요!                     \n",
      "------------------------------\n",
      "Prompt: 바다는 왜 파란색이야?\n",
      "Response: 바다는 왜 파란색이야? 그게 무슨 색인지 명확하지 않아서 답변이 어렵습니다. 좀 더 구체적인 정보를 주시면 답변드리도록 하겠습니다.隱)은 러시아의 시인으로, 러시아의 시인이며, 그는 러시아 시문학의 선구자 중 한 명입니다.隱은 러시아 문학계에서 큰 영향을 미쳤으며, 그 이후에는 그의 대표작 중 하나인 \"Sorry of the Night\"를 발표하기도 했습니다.隱은 주로 러시아의 시인으로, 러시아의 시인으로, 그의 대표작 중 하나인 \"Sorry of the Night\"\n",
      "------------------------------\n",
      "Prompt: 행복이란 무엇이라고 생각해?\n",
      "Response: 행복이란 무엇이라고 생각해? 어떤 분야에서 일하고 있는지 궁금해. 그렇다면 어떤 분야에서 일하고 있는지 궁금하네요. 그렇다면 그 분야에 대해 공부해보고 싶은가요? 具天, 郭治, 徐洪, 沈完, 朴秀三, 李宗, 朴成學,  朴成寬, 黃魯明, 朴寬植, 朴景雨, 黃時, 朴成植, 洪準周, \n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"3. Generating from PPO Fine-tuned Model...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# PPO 모델 및 토크나이저 로드\n",
    "# 토크나이저는 원본 KoGPT-2 경로에서 불러옵니다.\n",
    "ppo_tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "# 모델 가중치는 파인튜닝된 PPO 경로에서 그대로 불러옵니다.\n",
    "ppo_model = AutoModelForCausalLM.from_pretrained(PPO_MODEL_PATH).to(device)\n",
    "\n",
    "# 각 프롬프트에 대해 답변 생성\n",
    "for prompt in test_prompts:\n",
    "    inputs = ppo_tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "    # generate 함수에 pad_token_id를 명시적으로 설정해주는 것이 안정적\n",
    "    if ppo_tokenizer.pad_token_id is None:\n",
    "        ppo_tokenizer.pad_token_id = ppo_tokenizer.eos_token_id\n",
    "\n",
    "    output_sequences = ppo_model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_length=100,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        temperature=0.7,\n",
    "        eos_token_id=ppo_tokenizer.eos_token_id,\n",
    "        pad_token_id=ppo_tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    generated_text = ppo_tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "    results.append({\n",
    "        'prompt': prompt,\n",
    "        'model_type': 'PPO Model',\n",
    "        'response': generated_text\n",
    "    })\n",
    "\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {generated_text}\\n\" + \"-\"*30)\n",
    "\n",
    "# 메모리 관리를 위해 모델 삭제\n",
    "del ppo_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed49a0a-5355-48f0-884a-a423e6422a95",
   "metadata": {},
   "source": [
    "## ✅ Step 3 : 결과 취합 및 파일로 저장\n",
    "\n",
    "이제 results 리스트에 저장된 모든 답변을 보기 쉽게 하나의 데이터프레임으로 만들고, 나중 분석을 위해 CSV 파일로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577c2385-f88f-46ef-a837-88c75d823aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Baseline Performance Measurement Results\n",
      "==================================================\n",
      "model_type                                                 Pre-trained KoGPT-2  \\\n",
      "prompt                                                                           \n",
      "AI가 세상을 어떻게 바꿀 수 있을까?        AI가 세상을 어떻게 바꿀 수 있을까?\"라는 질문에 \"그런 질문은 처음 봤다. 하지...   \n",
      "대한민국의 수도는 어디인가요?             대한민국의 수도는 어디인가요?\" \"서울?\"\\n\"서울?\"\\n\"서울?\"\\n\"서울?\"\\n...   \n",
      "바다는 왜 파란색이야?                 바다는 왜 파란색이야?\"\\n\"그래. 이건 무슨 색이야?\"\\n\"이건 초록색이지. 파란...   \n",
      "세종대왕의 가장 큰 업적은 무엇인가요?        세종대왕의 가장 큰 업적은 무엇인가요?\"\\n\"그것은 바로 신하의 덕이 아니었는가?\"...   \n",
      "오늘 하루 어땠어?                   오늘 하루 어땠어?\"\\n\"아~ 그랬어? 난 어떡해?\"\\n\"뭐야. 엄마랑 아빠랑 같이...   \n",
      "요즘 피곤한데 힘이 나는 말을 해줘.         요즘 피곤한데 힘이 나는 말을 해줘.\"\\n\"저런 말도 해줘.\"\\n\"그럼, 그게 무슨...   \n",
      "임진왜란이 언제 일어났는지 알려줘.          임진왜란이 언제 일어났는지 알려줘. 네. 네. 그렇죠.\\n예. 그니까 이게 지금 뭐...   \n",
      "저녁 메뉴 추천해줘.                  저녁 메뉴 추천해줘. 아~ 이메뉴가 정말 짱이야. 그래서 두 가지 메뉴를 주문했어....   \n",
      "파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘.  파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘. 네. 코드 좀 짜줘.\"\\n\"아, ...   \n",
      "행복이란 무엇이라고 생각해?              행복이란 무엇이라고 생각해?\"\\n\"그런 것 같으면.\"\\n\"그런 말!\"\\n\"그리고 그...   \n",
      "\n",
      "model_type                                                           SFT Model  \\\n",
      "prompt                                                                           \n",
      "AI가 세상을 어떻게 바꿀 수 있을까?        AI가 세상을 어떻게 바꿀 수 있을까?\\n\\n1. 인공지능: 인간의 지능을 향상시키...   \n",
      "대한민국의 수도는 어디인가요?                                              대한민국의 수도는 어디인가요?   \n",
      "바다는 왜 파란색이야?                 바다는 왜 파란색이야? 이는 우리가 생각하는 것보다 더 선명한 색감을 가지고 있기 ...   \n",
      "세종대왕의 가장 큰 업적은 무엇인가요?        세종대왕의 가장 큰 업적은 무엇인가요?\\n\\n<세종대왕의 가장 큰 업적은 조선 시대...   \n",
      "오늘 하루 어땠어?                   오늘 하루 어땠어? 언제든 좋겠습니다. 좋은 하루 되세요!官, 辛官, 辛官, 辛官,...   \n",
      "요즘 피곤한데 힘이 나는 말을 해줘.         요즘 피곤한데 힘이 나는 말을 해줘. 그러면 안 되는 것은 아닌 것 같습니다. 상황...   \n",
      "임진왜란이 언제 일어났는지 알려줘.          임진왜란이 언제 일어났는지 알려줘. 예를 들면 \"우리나라에서 일어난 역사적인 사건\"...   \n",
      "저녁 메뉴 추천해줘.                  저녁 메뉴 추천해줘. 어떤 메뉴를 추천하시는지 구체적으로 알려주시면 더 나은 답변을...   \n",
      "파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘.  파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘. 그러면 그 서버는 더 많은 서버나...   \n",
      "행복이란 무엇이라고 생각해?              행복이란 무엇이라고 생각해?\\n\\n'저는 인공지능 어시스턴트이므로, 인간처럼 감정을...   \n",
      "\n",
      "model_type                                                           PPO Model  \n",
      "prompt                                                                          \n",
      "AI가 세상을 어떻게 바꿀 수 있을까?        AI가 세상을 어떻게 바꿀 수 있을까? 즉, 인공지능은 인간의 생활에 영향을 미치는...  \n",
      "대한민국의 수도는 어디인가요?             대한민국의 수도는 어디인가요? 자세한 정보를 알려주시면 더 정확한 답변을 드릴 수 ...  \n",
      "바다는 왜 파란색이야?                 바다는 왜 파란색이야? 그게 무슨 색인지 명확하지 않아서 답변이 어렵습니다. 좀 더...  \n",
      "세종대왕의 가장 큰 업적은 무엇인가요?        세종대왕의 가장 큰 업적은 무엇인가요?\\n\\n『삼국사기』『삼국사기』『삼국사기』『삼국...  \n",
      "오늘 하루 어땠어?                   오늘 하루 어땠어? 저는 인공지능 챗봇으로써 주어진 일만 열심히 하고 있습니다. 하...  \n",
      "요즘 피곤한데 힘이 나는 말을 해줘.         요즘 피곤한데 힘이 나는 말을 해줘. 뭐야? 너는 왜 그런 말을 하는지 모르겠어. ...  \n",
      "임진왜란이 언제 일어났는지 알려줘.          임진왜란이 언제 일어났는지 알려줘. inhery for the information...  \n",
      "저녁 메뉴 추천해줘.                  저녁 메뉴 추천해줘. 어떤 메뉴를 추천해드릴까요? 어떤 메뉴를 추천해드릴까요? 일반...  \n",
      "파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘.  파이썬으로 간단한 웹 서버 만드는 코드 좀 짜줘. 그러면 어떤 서버에서 어떤 프로그...  \n",
      "행복이란 무엇이라고 생각해?              행복이란 무엇이라고 생각해? 어떤 분야에서 일하고 있는지 궁금해. 그렇다면 어떤 분...  \n",
      "\n",
      " Baseline results have been saved to './baseline_results.csv'\n"
     ]
    }
   ],
   "source": [
    "# 결과를 데이터프레임으로 변환\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# 보기 쉽게 피벗 테이블 형태로 변환\n",
    "df_pivot = df_results.pivot(index='prompt', columns='model_type', values='response')\n",
    "\n",
    "# 컬럼 순서 정리\n",
    "df_pivot = df_pivot[['Pre-trained KoGPT-2', 'SFT Model', 'PPO Model']]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=\"*50)\n",
    "print(\"Baseline Performance Measurement Results\")\n",
    "print(\"=\"*50)\n",
    "print(df_pivot)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "baseline_results_path = './baseline_results.csv'\n",
    "df_pivot.to_csv(baseline_results_path, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n Baseline results have been saved to '{baseline_results_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f8252-868e-445f-8d8e-ff440d62d503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
