{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x8sRPIuki9F2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UhqmD0nXi67v"
      },
      "outputs": [],
      "source": [
        "import os, re, string, sys, subprocess, random, gc\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _pip_install(pkg):\n",
        "    try:\n",
        "        __import__(pkg.split(\"==\")[0].replace(\"-\", \"_\"))\n",
        "    except Exception:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n",
        "\n",
        "for pkg in [\"torch\", \"tqdm\", \"scikit-learn\", \"summa==1.2.0\"]:\n",
        "    _pip_install(pkg)"
      ],
      "metadata": {
        "id": "FhYAWS-ni_HE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b-SQELIsi_2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from summa.summarizer import summarize as summa_summarize"
      ],
      "metadata": {
        "id": "daoUmzHxjCuB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "WUEOlkzAjH40"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"/content/News_Summary.csv\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH, encoding=\"utf-8\", low_memory=False)"
      ],
      "metadata": {
        "id": "7IPwZo-kjO0y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2HeFLCiOjZ8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_candidates = [c for c in df.columns if c.lower() in [\"ctext\", \"text\", \"article\", \"articles\"]]\n",
        "tgt_candidates = [c for c in df.columns if c.lower() in [\"headlines\", \"headline\", \"summary\", \"title\"]]\n",
        "\n",
        "if not src_candidates or not tgt_candidates:\n",
        "    raise ValueError(f\"본문/요약 컬럼을 찾지 못함. 본문 후보:{df.columns.tolist()} 중 'ctext'/'text', 요약은 'headlines'/'summary' 필요\")\n",
        "\n",
        "SRC_COL, TGT_COL = src_candidates[0], tgt_candidates[0]\n",
        "\n",
        "df[SRC_COL] = df[SRC_COL].astype(str).str.strip()\n",
        "df[TGT_COL] = df[TGT_COL].astype(str).str.strip()\n",
        "df = df.replace({\"None\": np.nan, \"nan\": np.nan}).dropna(subset=[SRC_COL, TGT_COL]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "HLhy478FjaIZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MY8oDhLjjfzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _wc(s): return len(s.split())\n",
        "print(f\"[분석] 본문 평균 길이: {df[SRC_COL].map(_wc).mean():.1f}, 요약 평균 길이: {df[TGT_COL].map(_wc).mean():.1f}, 샘플: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgkKnr8Rjf7r",
        "outputId": "2b13ad01-938b-4a2c-ec62-ddc6e6357749"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[분석] 본문 평균 길이: 58.2, 요약 평균 길이: 9.6, 샘플: 98401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RrFwYSl-jiFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EN_STOPS = set(\"\"\"\n",
        "a about above after again against all am an and any are aren't as at be because been\n",
        "before being below between both but by can't cannot could couldn't did didn't do does\n",
        "doesn't doing don't down during each few for from further had hadn't has hasn't have\n",
        "haven't having he he'd he'll he's her here here's hers herself him himself his how\n",
        "how's i i'd i'll i'm i've if in into is isn't it it's its itself let's me more most\n",
        "mustn't my myself no nor not of off on once only or other ought our ours ourselves\n",
        "out over own same shan't she she'd she'll she's should shouldn't so some such than\n",
        "that that's the their theirs them themselves then there there's these they they'd\n",
        "they'll they're they've this those through to too under until up very was wasn't we\n",
        "we'd we'll we're we've were weren't what what's when when's where where's which while\n",
        "who who's whom why why's with won't would wouldn't you you'd you'll you're you've your\n",
        "yours yourself yourselves\n",
        "\"\"\".split())\n",
        "\n",
        "PUNCT_TABLE = str.maketrans(\"\", \"\", string.punctuation)"
      ],
      "metadata": {
        "id": "Xzm7dLs4jiNH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WWwHvyjPjms_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_tokenize(text: str):\n",
        "    # 알파벳 단어만 추출\n",
        "    return re.findall(r\"[A-Za-z]+\", text)"
      ],
      "metadata": {
        "id": "sY9ni156kl50"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(s: str, remove_stopwords=False, lower=True):\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    x = s\n",
        "    x = re.sub(r\"<.*?>\", \" \", x)  # HTML\n",
        "    x = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", x)  # URL\n",
        "    x = x.replace(\"\\u200b\", \" \").replace(\"\\xa0\", \" \")\n",
        "    if lower: x = x.lower()\n",
        "    x = re.sub(r\"[^a-z\\s]\", \" \", x)  # 숫자/기호 제거, 영문만\n",
        "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
        "    toks = simple_tokenize(x)\n",
        "    if remove_stopwords:\n",
        "        toks = [t for t in toks if t not in EN_STOPS]\n",
        "    return \" \".join(toks)"
      ],
      "metadata": {
        "id": "HYdVJceVkqSi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IzCo0cz8ktF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 본문 불용어 제거 O, 요약 불용어 제거 X\n",
        "df[\"src_clean\"] = df[SRC_COL].apply(lambda s: normalize_text(s, remove_stopwords=True))\n",
        "df[\"tgt_clean\"] = df[TGT_COL].apply(lambda s: normalize_text(s, remove_stopwords=False))\n",
        "\n",
        "# 너무 짧거나 긴 샘플 제거\n",
        "df = df[(df[\"src_clean\"].str.split().map(len) >= 30) & (df[\"tgt_clean\"].str.split().map(len).between(4, 20))]\n",
        "df = df.reset_index(drop=True)\n",
        "print(f\"[정제] 필터 후 샘플 수: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIcF01RxjnNf",
        "outputId": "e70f034d-a250-4ef9-c1e9-b0f2784739da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[정제] 필터 후 샘플 수: 94794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TdmFiaI_jqrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in list(df.columns):\n",
        "    if col not in [\"src_clean\", \"tgt_clean\"]:\n",
        "        try: del df[col]\n",
        "        except: pass\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NphHAVA3jrQT",
        "outputId": "2df2348c-19ca-4aae-8e72-ba01a6f9bff5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gt1yLF35jtw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(df[[\"src_clean\", \"tgt_clean\"]], test_size=0.1, random_state=SEED, shuffle=True)\n",
        "\n",
        "# 개발 모드: 큰 데이터면 일부만 사용 (RAM 부족시 숫자를 더 줄이세요)\n",
        "USE_N = 20000\n",
        "if len(train_df) > USE_N:\n",
        "    train_df = train_df.sample(USE_N, random_state=SEED).reset_index(drop=True)\n",
        "if len(val_df) > USE_N//10:\n",
        "    val_df = val_df.sample(USE_N//10, random_state=SEED).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "lQKHOMRvjt5J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9tRdlXmyk032"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(texts, max_size=20000, min_freq=2, specials=(\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\")):\n",
        "    counter = Counter()\n",
        "    for t in texts:\n",
        "        counter.update(t.split())\n",
        "    words = [w for w, c in counter.items() if c >= min_freq]\n",
        "    words = sorted(words, key=lambda w: (-counter[w], w))\n",
        "    words = words[:max_size - len(specials)]\n",
        "    itos = list(specials) + words\n",
        "    stoi = {w:i for i,w in enumerate(itos)}\n",
        "    return stoi, itos\n",
        "\n",
        "SRC_STOI, SRC_ITOS = build_vocab(train_df[\"src_clean\"].tolist(), max_size=20000, min_freq=2)\n",
        "TGT_STOI, TGT_ITOS = build_vocab(train_df[\"tgt_clean\"].tolist(), max_size=10000, min_freq=2)\n",
        "PAD_IDX, SOS_IDX, EOS_IDX, UNK_IDX = 0, 1, 2, 3"
      ],
      "metadata": {
        "id": "CR_jCEOnk1fo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wb46Cg9Ek6PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SRC_LEN = 120\n",
        "MAX_TGT_LEN = 20"
      ],
      "metadata": {
        "id": "uiBU89Zyk6XE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(s, stoi, max_len, add_sos=False, add_eos=False):\n",
        "    ids = [stoi.get(t, UNK_IDX) for t in s.split()]\n",
        "    if add_sos: ids = [SOS_IDX] + ids\n",
        "    if add_eos: ids = ids + [EOS_IDX]\n",
        "    ids = ids[:max_len]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [PAD_IDX] * (max_len - len(ids))\n",
        "    return ids"
      ],
      "metadata": {
        "id": "YQzGPE7yk8aw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummDataset(Dataset):\n",
        "    def __init__(self, df_):\n",
        "        self.src = df_[\"src_clean\"].tolist()\n",
        "        self.tgt = df_[\"tgt_clean\"].tolist()\n",
        "    def __len__(self): return len(self.src)\n",
        "    def __getitem__(self, i):\n",
        "        src_ids = encode_sentence(self.src[i], SRC_STOI, MAX_SRC_LEN, add_eos=True)\n",
        "        tgt_in  = encode_sentence(self.tgt[i], TGT_STOI, MAX_TGT_LEN, add_sos=True)\n",
        "        tgt_out = encode_sentence(self.tgt[i], TGT_STOI, MAX_TGT_LEN, add_eos=True)\n",
        "        return torch.tensor(src_ids), torch.tensor(tgt_in), torch.tensor(tgt_out)"
      ],
      "metadata": {
        "id": "UzoDKIvqk-ub"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds = SummDataset(train_df), SummDataset(val_df)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=2)"
      ],
      "metadata": {
        "id": "Aq0YKUgdlCaX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vJDYPnfAlD2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMB_SRC = 96\n",
        "EMB_TGT = 96\n",
        "HID = 128\n",
        "ENC_LAYERS = 1\n",
        "DEC_LAYERS = 1\n",
        "DROPOUT = 0.2"
      ],
      "metadata": {
        "id": "as51PqnBlD9y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid, num_layers=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid, num_layers=num_layers, batch_first=True,\n",
        "                            bidirectional=True, dropout=0 if num_layers==1 else dropout)\n",
        "        self.fc_h = nn.Linear(hid*2, hid)\n",
        "        self.fc_c = nn.Linear(hid*2, hid)\n",
        "    def forward(self, src):\n",
        "        emb = self.emb(src)                       # (B,S,E)\n",
        "        outputs, (h, c) = self.lstm(emb)          # outputs: (B,S,2H)\n",
        "        h_cat = torch.cat((h[-2], h[-1]), dim=1)  # (B,2H)\n",
        "        c_cat = torch.cat((c[-2], c[-1]), dim=1)\n",
        "        h0 = torch.tanh(self.fc_h(h_cat)).unsqueeze(0)  # (1,B,H)\n",
        "        c0 = torch.tanh(self.fc_c(c_cat)).unsqueeze(0)  # (1,B,H)\n",
        "        return outputs, (h0, c0)"
      ],
      "metadata": {
        "id": "rg8MrRtelIo8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k9ZnjGP9lKdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, enc_hid, dec_hid):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(enc_hid, dec_hid)\n",
        "        self.W2 = nn.Linear(dec_hid, dec_hid)\n",
        "        self.v  = nn.Linear(dec_hid, 1, bias=False)\n",
        "    def forward(self, enc_outputs, dec_hidden):\n",
        "        # enc_outputs: (B,S,2H), dec_hidden: (1,B,H)->(B,H)\n",
        "        dec_hidden = dec_hidden.transpose(0, 1)  # (B,H)\n",
        "        score = self.v(torch.tanh(self.W1(enc_outputs) + self.W2(dec_hidden).unsqueeze(1))).squeeze(-1)  # (B,S)\n",
        "        attn  = torch.softmax(score, dim=1).unsqueeze(-1)   # (B,S,1)\n",
        "        ctx   = torch.sum(attn * enc_outputs, dim=1)        # (B,2H)  ← S 축 합산 (핵심!)\n",
        "        return ctx, attn"
      ],
      "metadata": {
        "id": "dZLQFTx7lKld"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, enc_hid, dec_hid, num_layers=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
        "        self.attn = AdditiveAttention(enc_hid, dec_hid)\n",
        "        self.lstm = nn.LSTM(emb_dim + enc_hid, dec_hid, num_layers=num_layers, batch_first=True,\n",
        "                            dropout=0 if num_layers==1 else dropout)\n",
        "        self.fc_out = nn.Linear(dec_hid, vocab_size)\n",
        "    def forward(self, y_prev, hidden, cell, enc_outputs):\n",
        "        if y_prev.dim() == 1:\n",
        "            y_prev = y_prev.unsqueeze(1)\n",
        "        y_prev = y_prev.long()\n",
        "        emb = self.emb(y_prev)                 # (B,1,E)\n",
        "        ctx, _ = self.attn(enc_outputs, hidden)\n",
        "        if ctx.dim() == 3:                     # 안전가드 (혹시라도)\n",
        "            ctx = ctx.sum(dim=1)\n",
        "        x = torch.cat([emb, ctx.unsqueeze(1)], dim=-1)  # (B,1,E+2H)\n",
        "        out, (h, c) = self.lstm(x, (hidden, cell))      # out: (B,1,H)\n",
        "        logits = self.fc_out(out.squeeze(1))            # (B,V)\n",
        "        return logits, h, c"
      ],
      "metadata": {
        "id": "x_Eac5mQlNjX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, sos_idx=SOS_IDX, eos_idx=EOS_IDX, pad_idx=PAD_IDX, max_tgt_len=MAX_TGT_LEN):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.sos = sos_idx; self.eos = eos_idx; self.pad = pad_idx\n",
        "        self.max_tgt_len = max_tgt_len\n",
        "    def forward(self, src, tgt_in=None, teacher_forcing=0.5):\n",
        "        enc_outputs, (h, c) = self.encoder(src)\n",
        "        B = src.size(0)\n",
        "        y = torch.full((B,1), self.sos, dtype=torch.long, device=src.device)\n",
        "        outputs = []\n",
        "        steps = self.max_tgt_len if tgt_in is None else tgt_in.size(1)\n",
        "        for t in range(steps):\n",
        "            logits, h, c = self.decoder(y, h, c, enc_outputs)\n",
        "            outputs.append(logits.unsqueeze(1))\n",
        "            if tgt_in is not None and random.random() < teacher_forcing:\n",
        "                y = tgt_in[:, t].unsqueeze(1)\n",
        "            else:\n",
        "                y = logits.argmax(-1, keepdim=True)\n",
        "        return torch.cat(outputs, dim=1)  # (B,T,V)\n",
        "    @torch.no_grad()\n",
        "    def generate(self, src, max_len=None):\n",
        "        self.eval()\n",
        "        enc_outputs, (h, c) = self.encoder(src)\n",
        "        B = src.size(0)\n",
        "        y = torch.full((B,1), self.sos, dtype=torch.long, device=src.device)\n",
        "        outputs = []\n",
        "        max_len = max_len or self.max_tgt_len\n",
        "        for _ in range(max_len):\n",
        "            logits, h, c = self.decoder(y, h, c, enc_outputs)\n",
        "            nxt = logits.argmax(-1, keepdim=True)\n",
        "            outputs.append(nxt)\n",
        "            y = nxt\n",
        "        gen = torch.cat(outputs, dim=1)  # (B,T)\n",
        "        # EOS 잘라내기\n",
        "        result = []\n",
        "        for seq in gen.tolist():\n",
        "            out = []\n",
        "            for tok in seq:\n",
        "                if tok == self.eos: break\n",
        "                if tok not in (self.pad, self.sos):\n",
        "                    out.append(tok)\n",
        "            result.append(out)\n",
        "        return result"
      ],
      "metadata": {
        "id": "ciSBYRfllPYd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENC = Encoder(len(SRC_ITOS), EMB_SRC, HID, num_layers=ENC_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
        "DEC = Decoder(len(TGT_ITOS), EMB_TGT, enc_hid=HID*2, dec_hid=HID, num_layers=DEC_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
        "model = Seq2Seq(ENC, DEC).to(DEVICE)"
      ],
      "metadata": {
        "id": "yGiaPOOelRLs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
        "scaler = GradScaler(enabled=torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYmA2VlLlXXO",
        "outputId": "092d45df-1cb5-4338-c341-d7964483ec00"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-25088130.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yDyf63yHlmWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GRAD_ACCUM_STEPS = 4   # 16 * 4 = 64 효과 배치\n",
        "MAX_NORM = 1.0\n",
        "EPOCHS = 3"
      ],
      "metadata": {
        "id": "Gpg8N7CSlZpo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(loader, train=True):\n",
        "    model.train(train)\n",
        "    total = 0.0\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    for step, (src, tgt_in, tgt_out) in enumerate(tqdm(loader, desc=\"train\" if train else \"valid\"), start=1):\n",
        "        src, tgt_in, tgt_out = src.to(DEVICE), tgt_in.to(DEVICE), tgt_out.to(DEVICE)\n",
        "        with autocast(enabled=torch.cuda.is_available()):\n",
        "            logits = model(src, tgt_in=tgt_in, teacher_forcing=0.5 if train else 0.0)\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), tgt_out.view(-1))\n",
        "            loss = loss / (GRAD_ACCUM_STEPS if train else 1)\n",
        "        if train:\n",
        "            scaler.scale(loss).backward()\n",
        "            if step % GRAD_ACCUM_STEPS == 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_NORM)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "        total += loss.item() * (GRAD_ACCUM_STEPS if train else 1)\n",
        "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "    return total / max(1, len(loader))"
      ],
      "metadata": {
        "id": "JW373o8Xloo4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses = [], []\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr = run_epoch(train_loader, train=True)\n",
        "    vl = run_epoch(val_loader, train=False)\n",
        "    train_losses.append(tr); val_losses.append(vl)\n",
        "    print(f\"[{ep}/{EPOCHS}] Train {tr:.4f} | Val {vl:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIGmuepfm4Q5",
        "outputId": "18caccfd-620d-4f61-e6cd-7ac41cb1f94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/1250 [00:00<?, ?it/s]/tmp/ipython-input-3239269368.py:7: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n",
            "train:  21%|██        | 263/1250 [24:30<3:55:49, 14.34s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "arDAwQJmlwAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 그래프 출력\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(range(1, EPOCHS+1), train_losses, label=\"Train\")\n",
        "plt.plot(range(1, EPOCHS+1), val_losses, label=\"Val\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()  # 저장 대신 바로 출력"
      ],
      "metadata": {
        "id": "Em9Kr0O3tAUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IDX2TGT = {i:w for i,w in enumerate(TGT_ITOS)}\n",
        "\n",
        "def decode_ids(ids):\n",
        "    return \" \".join([IDX2TGT.get(i, \"<unk>\") for i in ids])\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_texts(df_, n_samples=20):\n",
        "    sample = df_.sample(n=min(n_samples, len(df_)), random_state=SEED).reset_index(drop=True)\n",
        "    src_batch = [encode_sentence(s, SRC_STOI, MAX_SRC_LEN, add_eos=True) for s in sample[\"src_clean\"]]\n",
        "    src_batch = torch.tensor(src_batch, device=DEVICE)\n",
        "    gen_ids = model.generate(src_batch, max_len=MAX_TGT_LEN)\n",
        "    gen_texts = []\n",
        "    for ids in gen_ids:\n",
        "        gen_texts.append(\" \".join([IDX2TGT.get(i, \"<unk>\") for i in ids]))\n",
        "    return sample, gen_texts\n",
        "\n",
        "sample_df, abstractive_out = generate_texts(val_df, n_samples=30)"
      ],
      "metadata": {
        "id": "FncyC5ixtDlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def key_terms(text, top_k=8):\n",
        "    toks = [t for t in simple_tokenize(text.lower()) if t not in EN_STOPS]\n",
        "    freq = Counter(toks)\n",
        "    return [w for w,_ in freq.most_common(top_k)]\n",
        "\n",
        "def keyword_coverage(ref_headline, pred):\n",
        "    ref = set(key_terms(ref_headline, top_k=8))\n",
        "    hyp = set([t for t in simple_tokenize(pred.lower()) if t not in EN_STOPS])\n",
        "    if not ref: return 0.0\n",
        "    return len(ref & hyp) / len(ref)"
      ],
      "metadata": {
        "id": "hFUOcOdRtGol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grammar_completeness(s):\n",
        "    # 간이 문법 점수 (POS 미사용): 동사/조동사 단어 포함 + 알파비율 + 유니크비율 + 끝마침부호\n",
        "    if not s.strip(): return 0.0\n",
        "    toks = simple_tokenize(s)\n",
        "    if not toks: return 0.0\n",
        "    verbs_hint = {\"is\",\"are\",\"was\",\"were\",\"be\",\"being\",\"been\",\"have\",\"has\",\"had\",\n",
        "                  \"do\",\"does\",\"did\",\"will\",\"would\",\"can\",\"could\",\"should\",\"may\",\"might\",\"must\"}\n",
        "    has_verb = 1.0 if any(t in verbs_hint or t.endswith(\"ed\") or t.endswith(\"ing\") for t in toks) else 0.0\n",
        "    alpha_ratio = 1.0  # 이미 알파만 사용\n",
        "    uniq_ratio = len(set(toks)) / max(1,len(toks))\n",
        "    ends_ok = 1.0 if s.strip()[-1:] in [\".\",\"!\",\"?\"] else 0.0\n",
        "    score = 0.45*has_verb + 0.25*alpha_ratio + 0.25*uniq_ratio + 0.05*ends_ok\n",
        "    return float(np.clip(score, 0.0, 1.0))"
      ],
      "metadata": {
        "id": "6FvfJ-P1tIuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for i, row in sample_df.iterrows():\n",
        "    head = row[\"tgt_clean\"]\n",
        "    abs_sum = abstractive_out[i]\n",
        "\n",
        "    # Step 5. Summa 추출요약 (가볍게, 실패시 앞 2문장 대체)\n",
        "    try:\n",
        "        ext_sum = summa_summarize(row[\"src_clean\"], ratio=0.25)\n",
        "        if not ext_sum:\n",
        "            # 아주 짧은 텍스트는 비어올 수 있음 → 앞 n단어 40개 fallback\n",
        "            ext_sum = \" \".join(row[\"src_clean\"].split()[:40])\n",
        "    except Exception:\n",
        "        ext_sum = \" \".join(row[\"src_clean\"].split()[:40])\n",
        "\n",
        "    rows.append({\n",
        "        \"original_headline\": head,\n",
        "        \"abstractive_summary\": abs_sum,\n",
        "        \"extractive_summary\": ext_sum,\n",
        "        \"keyword_coverage_abs\": round(keyword_coverage(head, abs_sum), 3),\n",
        "        \"keyword_coverage_ext\": round(keyword_coverage(head, ext_sum), 3),\n",
        "        \"grammar_score_abs\": round(grammar_completeness(abs_sum), 3),\n",
        "        \"grammar_score_ext\": round(grammar_completeness(ext_sum), 3),\n",
        "        \"headline_key_terms\": \", \".join(key_terms(head, top_k=8)),\n",
        "    })"
      ],
      "metadata": {
        "id": "DWNtXO8HtKLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.DataFrame(rows)\n",
        "print(result_df)"
      ],
      "metadata": {
        "id": "CfoObv0htMqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ymfj31btYJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPWjCrNvtX7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}